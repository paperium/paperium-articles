<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <link rel="stylesheet" href="/paperium-articles/assets/article_detail.css"> 

<title>ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D R</title>

<meta name="keywords" content="monocular image sequence reconstruction,  real-to-sim digitization pipeline,  AR/VR environment mapping,  robotics SLAM integration,  per-scene optimi">

<meta name="description" content="monocular image sequence reconstruction,  real-to-sim digitization pipeline,  AR/VR environment mapping,  robotics SLAM integration,  per-scene optimi">

</head>
<body>
    <div class="container my-5">
        <div class="row">
    <div class="header-nav text-center">
        <a href="/">Home</a> 
        <span class="separator">|</span> 
        <a href="#">Article</a> 
    </div>

    <div class="article-container">
        <div class="article-tags-row">
            <span class="article-category-badge ">Artificial Intelligence</span>
            <span class="article-category-badge">arXiv</span>
        </div>
        <article id="MainArticle" class="details-body customeArticle" itemscope itemtype="https://schema.org/Article">
            <h1 itemprop="headline" class="article-title">
                ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with
Structured Scene Representation
            </h1> 

            <div class="article-author-row">
                <span class="author-name">
                    <img src="/paperium-articles/assets/avatar.png" alt="Author" class="author-icon"> 
                    <span class="authorList">
                        Guanghao Li, Kerui Ren, Linning Xu, Zhewen Zheng, Changjian Jiang, Xin Gao, Bo Dai, Jian Pu, Mulin Yu, Jiangmiao Pang
                    </span>
                </span>
            </div>
            <p class="publish-date">
                              13 Oct 2025&nbsp;&nbsp;&nbsp;&nbsp;  3 min read 
            </p>
                            <div class="article-image-wrapper">
                                <figure id="authorsImage"  >
                                    <img class="article-main-image" itemprop="image" src="https://paperium.net/Media/Articles/img/41_7efbcd60-7908-4b70-8340-aabe66f374ef.jpg" class="object-center object-cover" 
                                    alt="undefined" >
                                </figure>
                                 <p class="image-caption">AI-generated image, based on the article abstract</p>
                            </div>

            <div id="QuickInsightWapper" class="mb-4"  itemprop="abstract">
               <h2>
     
     <svg fill="#000000" width="30px" height="30px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg">
<title>paper-plane</title>
<path d="M0 14.016l9.216 6.912 18.784-16.928-14.592 20.064 10.592 7.936 8-32zM8 32l6.016-4-6.016-4v8z"></path>
</svg>
   Quick Insight
       </h2>
            <h3>ARTDECO: Turning Real‚ÄëWorld Spaces into Live 3D Models in a Snap</h3>
<p>
Ever wondered how your phone could instantly turn a room into a digital twin? <strong>Scientists have unveiled</strong> a new system called <strong>ARTDECO</strong> that does exactly that‚Äîbuilding detailed 3‚ÄëD reconstructions on the fly from a single moving camera. Imagine walking through a museum while your device creates a perfect virtual copy in real time, ready for AR games or robot navigation. <strong>What makes it special</strong> is a clever blend of fast, feed‚Äëforward AI with the reliability of classic SLAM techniques, using ‚ÄúGaussian clouds‚Äù that act like tiny, shape‚Äëshifting building blocks. It‚Äôs like stacking LEGO bricks that automatically snap into the right place as you move. The result? Interactive speed comparable to your favorite VR apps, yet with the visual quality of painstaking, per‚Äëscene designs. This breakthrough could soon let anyone digitize their surroundings for immersive AR/VR experiences, smarter robots, or instant virtual tours‚Äîright from a phone. The future of live, high‚Äëfidelity 3‚ÄëD worlds is already here, waiting to be captured.<br><br>
Ready to see your world in a whole new dimension? üåç‚ú®
</p>
           </div> 
           <hr/>
  <div id="ShortReviewWapper" class="mb-4" itemprop="articleBody">
 <h2>
     <svg fill="#000000" width="30px" height="30px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg">
<title>paper-plane</title>
<path d="M0 14.016l9.216 6.912 18.784-16.928-14.592 20.064 10.592 7.936 8-32zM8 32l6.016-4-6.016-4v8z"></path>
</svg>
   Short Review
       </h2>
        <h2>Overview of ARTDECO: Bridging SLAM and Feed‚ÄëForward Models for Real‚ÄëTime 3D Reconstruction</h2>
<p>ARTDECO tackles the enduring challenge of <strong>on-the-fly 3D reconstruction from monocular sequences</strong>, a cornerstone for AR/VR, robotics, and real‚Äëto‚Äësim workflows. The framework fuses fast feed‚Äëforward foundation models with robust SLAM pipelines to balance speed and accuracy. Pose estimation and point prediction are driven by pretrained 3D models, while a novel Gaussian decoder translates multi‚Äëscale features into structured 3D Gaussians. To maintain fidelity without sacrificing efficiency, ARTDECO introduces a hierarchical Gaussian representation coupled with a LoD‚Äëaware rendering strategy that reduces redundancy while enhancing visual detail. Experiments across eight indoor and outdoor benchmarks demonstrate interactive performance on par with traditional SLAM, robustness comparable to feed‚Äëforward systems, and reconstruction quality approaching per‚Äëscene optimization. The result is a practical pathway toward real‚Äëtime digitization of complex environments with both geometric precision and high visual fidelity.</p>

<h3>Critical Evaluation</h3>
<p><strong>Strengths</strong></p>
<p>The integration of foundation models with SLAM leverages the best of both worlds, yielding competitive speed without compromising accuracy. The Gaussian decoder is a clever architectural choice that preserves spatial coherence while enabling efficient rendering. Extensive benchmarking across diverse scenes strengthens the claim of generalizability.</p>

<p><strong>Weaknesses</strong></p>
<p>The reliance on pretrained 3D models may limit performance in highly novel or texture‚Äëpoor environments where training data are scarce. The paper offers limited insight into memory consumption and scalability on commodity hardware, which could hinder adoption in resource‚Äëconstrained settings.</p>

<p><strong>Implications</strong></p>
<p>ARTDECO‚Äôs hybrid approach signals a shift toward modular pipelines that can be tuned for either speed or fidelity as application demands dictate. The hierarchical Gaussian representation may inspire future work on multi‚Äëresolution 3D representations beyond reconstruction, such as real‚Äëtime scene editing or physics simulation.</p>

<h3>Conclusion</h3>
<p>The article presents a compelling synthesis of feed‚Äëforward inference and SLAM‚Äëstyle optimization, achieving a rare balance between interactivity and quality. While some practical deployment details remain underexplored, the methodological innovations‚Äîparticularly the Gaussian decoder and LoD‚Äëaware rendering‚Äîoffer valuable contributions to the field of real‚Äëtime 3D reconstruction.</p>

<h3>Readability</h3>
<p>The text is organized into clear sections with concise sentences that facilitate quick scanning. Key concepts are highlighted in bold, guiding readers toward the most impactful ideas without overwhelming them with jargon. This structure encourages deeper engagement and reduces bounce rates by making complex technical content approachable for a professional audience.</p>
  </div>
  <div id = "keywordsWapper" class="mb-4">
    <h3>Keywords</h3>
    <ul>
  <li>monocular image sequence reconstruction</li><li> real-to-sim digitization pipeline</li><li> AR/VR environment mapping</li><li> robotics SLAM integration</li><li> per-scene optimization tradeoffs</li><li> feed-forward foundation model inference</li><li> Gaussian decoder architecture</li><li> multi-scale feature fusion</li><li> structured 3D Gaussian representation</li><li> hierarchical Gaussian hierarchy</li><li> LoD-aware rendering technique</li><li> interactive real-time performance</li><li> robustness to scene variation</li><li> high visual fidelity reconstruction</li><li> benchmark evaluation on indoor/outdoor scenes</li>
</ul>

  </div>
  <div id="linktoWebsiteWrapper">
   <p>
Read article comprehensive review in Paperium.net:
<a href="https://paperium.net/article/en/32/artdeco-towards-efficient-and-high-fidelity-on-the-fly-3d-reconstruction-withstructured-scene-repres" target="_blank" title=" ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with
Structured Scene Representation">
    ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with
Structured Scene Representation
</a>
</p> 
 
</div>

<p class="mt-5">
    ü§ñ This analysis and review was primarily generated and structured by an AI . The content is provided for informational and quick-review purposes.
</p>
            <div class="my-5">
       <h2 class="lead text-center mb-5">Paperium AI Analysis & Review of Latest Scientific Research Articles </h2>
<h3>More Artificial Intelligence Article Reviews </h3>
       <div class="row row-cols-1 row-cols-md-2 row-cols-lg-3 g-4" id="articles-container" itemscope itemtype="https://schema.org/ItemList" >

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/45_fd73bbb4-87ef-4e67-8fbf-63582c2e2369.jpg" class="card-img-top" alt="UniMMVSR: A Unified Multi-Modal Framework for Cascaded Video Super-Resolution" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Shian Du
          </div>
          <div class="article-meta-text">
            13 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/36-UniMMVSR-A-Unified-Multi-Modal-Framework-for-Cascaded-Video-Super-Resolution/index.html"  title="UniMMVSR: A Unified Multi-Modal Framework for Cascaded Video Super-Resolution">
          <h3 class="card-title pb-2" itemprop="headline">UniMMVSR: A Unified Multi-Modal Framework for Cascaded Video Super-Resolution</h3>
        </a>
        <a 
          href="/paperium-articles/articles/36-UniMMVSR-A-Unified-Multi-Modal-Framework-for-Cascaded-Video-Super-Resolution/index.html"
          title="UniMMVSR: A Unified Multi-Modal Framework for Cascaded Video Super-Resolution"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/34_df8ef4c9-d86b-43ef-a13b-8e0be10197ca.jpg" class="card-img-top" alt="Meta-Awareness Enhances Reasoning Models: Self-Alignment Reinforcement Learning" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Yoonjeon Kim
          </div>
          <div class="article-meta-text">
            13 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/25-Meta-Awareness-Enhances-Reasoning-Models-Self-Alignment-Reinforcement-Learning/index.html"  title="Meta-Awareness Enhances Reasoning Models: Self-Alignment Reinforcement Learning">
          <h3 class="card-title pb-2" itemprop="headline">Meta-Awareness Enhances Reasoning Models: Self-Alignment Reinforcement Learning</h3>
        </a>
        <a 
          href="/paperium-articles/articles/25-Meta-Awareness-Enhances-Reasoning-Models-Self-Alignment-Reinforcement-Learning/index.html"
          title="Meta-Awareness Enhances Reasoning Models: Self-Alignment Reinforcement Learning"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/52_614ec427-1eeb-4e53-a8fa-b944a22a8433.jpg" class="card-img-top" alt="Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon
Tasks" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Cheng Yang
          </div>
          <div class="article-meta-text">
            13 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/43-Learning-on-the-Job-An-Experience-Driven-Self-Evolving-Agent-for-Long-Horizon-Tasks/index.html"  title="Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon
Tasks">
          <h3 class="card-title pb-2" itemprop="headline">Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon
Tasks</h3>
        </a>
        <a 
          href="/paperium-articles/articles/43-Learning-on-the-Job-An-Experience-Driven-Self-Evolving-Agent-for-Long-Horizon-Tasks/index.html"
          title="Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon
Tasks"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/103_6d67cf09-2d02-4cb6-923e-ae1ce0caa7b3.jpg" class="card-img-top" alt="A Goal Without a Plan Is Just a Wish: Efficient and Effective Global Planner
Training for Long-Horizon Agent Tasks" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Shuzheng Si
          </div>
          <div class="article-meta-text">
            13 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/99-A-Goal-Without-a-Plan-Is-Just-a-Wish-Efficient-and-Effective-Global-Planner-Training-for-Long-Hor/index.html"  title="A Goal Without a Plan Is Just a Wish: Efficient and Effective Global Planner
Training for Long-Horizon Agent Tasks">
          <h3 class="card-title pb-2" itemprop="headline">A Goal Without a Plan Is Just a Wish: Efficient and Effective Global Planner
Training for Long-Horizon Agent Tasks</h3>
        </a>
        <a 
          href="/paperium-articles/articles/99-A-Goal-Without-a-Plan-Is-Just-a-Wish-Efficient-and-Effective-Global-Planner-Training-for-Long-Hor/index.html"
          title="A Goal Without a Plan Is Just a Wish: Efficient and Effective Global Planner
Training for Long-Horizon Agent Tasks"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/79_1de8f843-9fc1-4119-9ffc-d19feeecb1f2.jpg" class="card-img-top" alt="D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied
AI" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Suwhan Choi
          </div>
          <div class="article-meta-text">
            13 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/75-D2E-Scaling-Vision-Action-Pretraining-on-Desktop-Data-for-Transfer-to-Embodied-AI/index.html"  title="D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied
AI">
          <h3 class="card-title pb-2" itemprop="headline">D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied
AI</h3>
        </a>
        <a 
          href="/paperium-articles/articles/75-D2E-Scaling-Vision-Action-Pretraining-on-Desktop-Data-for-Transfer-to-Embodied-AI/index.html"
          title="D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied
AI"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/117_d970e618-0451-46bb-b439-7a63cc49c70d.jpg" class="card-img-top" alt="Temporal Prompting Matters: Rethinking Referring Video Object Segmentation" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Ci-Siang Lin
          </div>
          <div class="article-meta-text">
            13 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/113-Temporal-Prompting-Matters-Rethinking-Referring-Video-Object-Segmentation/index.html"  title="Temporal Prompting Matters: Rethinking Referring Video Object Segmentation">
          <h3 class="card-title pb-2" itemprop="headline">Temporal Prompting Matters: Rethinking Referring Video Object Segmentation</h3>
        </a>
        <a 
          href="/paperium-articles/articles/113-Temporal-Prompting-Matters-Rethinking-Referring-Video-Object-Segmentation/index.html"
          title="Temporal Prompting Matters: Rethinking Referring Video Object Segmentation"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

       </div>
   </div>
        </article>
        
 

     
    </div>
    </div>
    </div>
  <link rel="stylesheet" href="/paperium-articles/assets/script1.js"> 
 
</body>
</html>