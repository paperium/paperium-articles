<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <link rel="stylesheet" href="/paperium-articles/assets/article_detail.css"> 
    <link rel="stylesheet" href="/paperium-articles/assets/StyleSheet.css" >

<title>Beyond Turn Limits: Training Deep Search Agents with Dynamic</title>

<meta name="keywords" content="DeepMiner framework,  multi-turn reasoning agents,  long-horizon interactions,  dynamic context management,  reinforcement learning for reasoning,  hi">

<meta name="description" content="DeepMiner framework,  multi-turn reasoning agents,  long-horizon interactions,  dynamic context management,  reinforcement learning for reasoning,  hi">

</head>
<body>
    <div class="container my-5">
        <div class="row">
    <div class="header-nav text-center">
        <a href="/paperium-articles/">Home</a> 
        <span class="separator">|</span> 
        <a href="#">Article</a> 
    </div>

    <div class="article-container">
        <div class="article-tags-row">
            <span class="article-category-badge ">Artificial Intelligence</span>
            <span class="article-category-badge">arXiv</span>
        </div>
        <article id="MainArticle" class="details-body customeArticle" itemscope itemtype="https://schema.org/Article">
            <h1 itemprop="headline" class="article-title">
                Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window
            </h1> 

            <div class="article-author-row">
                <span class="author-name">
                    <img src="/paperium-articles/assets/avatar.png" alt="Author" class="author-icon"> 
                    <span class="authorList">
                        Qiaoyu Tang, Hao Xiang, Le Yu, Bowen Yu, Yaojie Lu, Xianpei Han, Le Sun, WenJuan Zhang, Pengbo Wang, Shixuan Liu, Zhenru Zhang, Jianhong Tu, Hongyu Lin, Junyang Lin
                    </span>
                </span>
            </div>
            <p class="publish-date">
                              13 Oct 2025&nbsp;&nbsp;&nbsp;&nbsp;  3 min read 
            </p>
                            <div class="article-image-wrapper">
                                <figure id="authorsImage"  >
                                    <img class="article-main-image" itemprop="image" src="https://paperium.net/Media/Articles/img/57_88e59798-f6d7-4dcd-b41a-bd04a7b439a6.jpg" class="object-center object-cover" 
                                    alt="undefined" >
                                </figure>
                                 <p class="image-caption">AI-generated image, based on the article abstract</p>
                            </div>

            <div id="QuickInsightWapper" class="mb-4"  itemprop="abstract">
               <h2>
     
     <svg fill="#000000" width="30px" height="30px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg">
<title>paper-plane</title>
<path d="M0 14.016l9.216 6.912 18.784-16.928-14.592 20.064 10.592 7.936 8-32zM8 32l6.016-4-6.016-4v8z"></path>
</svg>
   Quick Insight
       </h2>
            <h3>New AI Trick Lets Chatbots Remember Longer Conversations</h3>
<p>
Ever wondered why virtual assistants sometimes forget what you just asked? <strong>Scientists have discovered</strong> a clever way to give them a memory boost. By training a system called <strong>DeepMiner</strong> with ultra‚Äëhard puzzles and a ‚Äúsliding window‚Äù that constantly shifts the focus, the AI can keep track of almost a hundred back‚Äëand‚Äëforth exchanges without losing the thread. Imagine a notebook that automatically flips pages as you write, so you never run out of space‚Äî that‚Äôs how the dynamic context window works. This breakthrough means search‚Äëhelp bots can stay on topic for much longer, delivering more accurate answers and smoother chats. The result? A jump from ordinary performance to a striking 33.5% success rate on tough benchmark tests, beating the previous best by nearly 20 points. <strong>It‚Äôs a game‚Äëchanger</strong> for everyday tools like voice assistants, customer‚Äëservice chats, and online search helpers. As AI learns to think more like us, the line between human conversation and machine dialogue keeps getting brighter. üåü
</p>
           </div> 
           <hr/>
  <div id="ShortReviewWapper" class="mb-4" itemprop="articleBody">
 <h2>
     <svg fill="#000000" width="30px" height="30px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg">
<title>paper-plane</title>
<path d="M0 14.016l9.216 6.912 18.784-16.928-14.592 20.064 10.592 7.936 8-32zM8 32l6.016-4-6.016-4v8z"></path>
</svg>
   Short Review
       </h2>
        <h2>Advancing Long-Horizon Reasoning in Multi-Turn AI Agents with DeepMiner</h2>

<p>The article introduces <strong>DeepMiner</strong>, a novel framework designed to enhance deep reasoning capabilities in multi-turn AI agents engaged in long-horizon interactions. Existing models often struggle with maintaining coherence and depth over extended conversational or task sequences, primarily due to limitations in handling continuously expanding contexts. DeepMiner addresses this by integrating a sophisticated training data generation method with an efficient context management strategy.</p>

<p>The core methodology involves two key innovations: a reverse construction method for generating high-difficulty, verifiable question-answer pairs from authentic web sources, and a dynamic sliding-window context manager. This approach enables the model to process complex information and sustain reasoning traces without relying on external summarization tools. Trained using reinforcement learning on Qwen3-32B, the resulting DeepMiner-32B agent demonstrates significant performance improvements across several challenging search agent benchmarks.</p>

<p>Specifically, DeepMiner achieves a 33.5% accuracy on BrowseComp-en, marking a nearly 20 percentage point lead over previous open-source agents. Consistent gains are also observed on BrowseComp-zh, XBench-DeepSearch, and GAIA. Crucially, its dynamic context management strategy facilitates sustained interactions of nearly 100 turns within a standard 32k context length, effectively overcoming a major bottleneck for current multi-turn interaction systems.</p>

<h2>Critical Evaluation of DeepMiner's Approach</h2>

<h3>Strengths</h3>
<p>DeepMiner's primary strength lies in its innovative approach to both data generation and context management. The <strong>reverse construction method</strong> for creating high-difficulty, multi-source QA pairs is particularly robust, ensuring that training data genuinely requires extended cross-document reasoning. This directly addresses the need for complex task data to foster advanced web-agent cognition, moving beyond simpler datasets like HotpotQA.</p>
<p>Furthermore, the <strong>dynamic sliding-window context manager</strong> is an elegant and efficient solution to the long-horizon interaction problem. By preserving reasoning traces without external summarization, it significantly reduces computational overhead and maintains the integrity of information over many turns. This strategy enables the agent to handle nearly 100 turns within typical context limits, a substantial improvement over existing systems.</p>
<p>The empirical results are compelling, showcasing substantial performance gains over other open-source agents and narrowing the gap with proprietary systems. The two-stage training pipeline, combining supervised fine-tuning with <strong>Group Relative Policy Optimization</strong>, provides a solid foundation for robust agent development.</p>

<h3>Weaknesses</h3>
<p>While impressive, the article could benefit from further exploration of the generalizability of its findings. The reliance on Qwen3-32B as the base model, though powerful, raises questions about how DeepMiner would perform with other foundational models. Additionally, the binary reward scheme (1 for correct, 0 for incorrect) in the reinforcement learning phase, while effective, might oversimplify the nuances of complex reasoning tasks, potentially overlooking partial successes or sophisticated intermediate steps.</p>
<p>The complexity and resource intensity of the multi-stage QA pair generation pipeline, involving entity-driven collection, multi-source synthesis, and rigorous filtering, could also be a practical limitation for broader adoption or replication by researchers with fewer computational resources.</p>

<h3>Implications</h3>
<p>DeepMiner represents a significant step forward in developing more capable and efficient <strong>multi-turn reasoning agents</strong>. Its innovations in data generation and context handling offer practical solutions to long-standing challenges in AI. The framework's ability to sustain deep interactions over extended horizons has profound implications for applications requiring sophisticated web search, complex problem-solving, and advanced conversational AI, potentially leading to more intelligent and reliable AI assistants.</p>

<h2>Conclusion</h2>
<p>DeepMiner offers a compelling and effective framework for enhancing <strong>long-horizon reasoning</strong> in AI agents. By tackling the dual challenges of generating high-quality, complex training data and efficiently managing dynamic contexts, it significantly pushes the boundaries of what open-source agents can achieve. This work not only delivers substantial performance improvements but also provides valuable insights into the design of future AI systems capable of more profound and sustained cognitive behaviors.</p>
  </div>
  <div id = "keywordsWapper" class="mb-4">
    <h3>Keywords</h3>
    <ul>
  <li>DeepMiner framework</li><li> multi-turn reasoning agents</li><li> long-horizon interactions</li><li> dynamic context management</li><li> reinforcement learning for reasoning</li><li> high-difficulty training tasks</li><li> reverse construction Q&A generation</li><li> context window optimization</li><li> search agent benchmarks</li><li> cognitive capabilities in AI</li><li> sliding window context</li><li> Qwen3-32B fine-tuning</li><li> addressing context limitations</li><li> verifiable training data</li><li> deep reasoning capabilities</li>
</ul>

  </div>
  <div id="linktoWebsiteWrapper">
   <p>
Read article comprehensive review in Paperium.net:
<a href="https://paperium.net/article/en/72/beyond-turn-limits-training-deep-search-agents-with-dynamic-context-window" target="_blank" title=" Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window">
    Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window
</a>
</p> 
 
</div>

<p class="mt-5">
    ü§ñ This analysis and review was primarily generated and structured by an AI . The content is provided for informational and quick-review purposes.
</p>
            <div class="my-5" id=similarWrapper>
       <h2 class="lead text-center mb-5" id="similarh2">Paperium AI Analysis & Review of Latest Scientific Research Articles </h2>
<h3 id="similarh3"> More Artificial Intelligence Article Reviews </h3>
       <div class="row row-cols-1 row-cols-md-2 row-cols-lg-3 g-4" id="articles-container" itemscope itemtype="https://schema.org/ItemList" >

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/272_08d26ee8-3fa2-405e-a2ab-150482ec6ccf.jpg" class="card-img-top" alt="Large Language Models Do NOT Really Know What They Don't Know" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Chi Seng Cheang
          </div>
          <div class="article-meta-text">
            17 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/259-Large-Language-Models-Do-NOT-Really-Know-What-They-Dont-Know/index.html"  title="Large Language Models Do NOT Really Know What They Don't Know">
          <h3 class="card-title pb-2" itemprop="headline">Large Language Models Do NOT Really Know What They Don't Know</h3>
        </a>
        <a 
          href="/paperium-articles/articles/259-Large-Language-Models-Do-NOT-Really-Know-What-They-Dont-Know/index.html"
          title="Large Language Models Do NOT Really Know What They Don't Know"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/155_07e0ffe2-354f-45f6-b828-ee91dde0e1e2.jpg" class="card-img-top" alt="Spotlight on Token Perception for Multimodal Reinforcement Learning" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Siyuan Huang
          </div>
          <div class="article-meta-text">
            14 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/144-Spotlight-on-Token-Perception-for-Multimodal-Reinforcement-Learning/index.html"  title="Spotlight on Token Perception for Multimodal Reinforcement Learning">
          <h3 class="card-title pb-2" itemprop="headline">Spotlight on Token Perception for Multimodal Reinforcement Learning</h3>
        </a>
        <a 
          href="/paperium-articles/articles/144-Spotlight-on-Token-Perception-for-Multimodal-Reinforcement-Learning/index.html"
          title="Spotlight on Token Perception for Multimodal Reinforcement Learning"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/166_df30bbbd-e8e8-4fc6-8c5c-9cd631d98f34.jpg" class="card-img-top" alt="Don't Just Fine-tune the Agent, Tune the Environment" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Siyuan Lu
          </div>
          <div class="article-meta-text">
            14 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/155-Dont-Just-Fine-tune-the-Agent-Tune-the-Environment/index.html"  title="Don't Just Fine-tune the Agent, Tune the Environment">
          <h3 class="card-title pb-2" itemprop="headline">Don't Just Fine-tune the Agent, Tune the Environment</h3>
        </a>
        <a 
          href="/paperium-articles/articles/155-Dont-Just-Fine-tune-the-Agent-Tune-the-Environment/index.html"
          title="Don't Just Fine-tune the Agent, Tune the Environment"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/182_a7914638-761b-49ed-a54a-11b5f9673c9c.jpg" class="card-img-top" alt="HUME: Measuring the Human-Model Performance Gap in Text Embedding Task" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Adnan El Assadi
          </div>
          <div class="article-meta-text">
            14 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/171-HUME-Measuring-the-Human-Model-Performance-Gap-in-Text-Embedding-Task/index.html"  title="HUME: Measuring the Human-Model Performance Gap in Text Embedding Task">
          <h3 class="card-title pb-2" itemprop="headline">HUME: Measuring the Human-Model Performance Gap in Text Embedding Task</h3>
        </a>
        <a 
          href="/paperium-articles/articles/171-HUME-Measuring-the-Human-Model-Performance-Gap-in-Text-Embedding-Task/index.html"
          title="HUME: Measuring the Human-Model Performance Gap in Text Embedding Task"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/172_c6e94e1e-7126-4041-a044-2ddeb233d696.jpg" class="card-img-top" alt="On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large
Vision-Language Models" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Hoigi Seo
          </div>
          <div class="article-meta-text">
            14 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/161-On-Epistemic-Uncertainty-of-Visual-Tokens-for-Object-Hallucinations-in-Large-Vision-Language-Mod/index.html"  title="On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large
Vision-Language Models">
          <h3 class="card-title pb-2" itemprop="headline">On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large
Vision-Language Models</h3>
        </a>
        <a 
          href="/paperium-articles/articles/161-On-Epistemic-Uncertainty-of-Visual-Tokens-for-Object-Hallucinations-in-Large-Vision-Language-Mod/index.html"
          title="On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large
Vision-Language Models"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/81_2e893ed5-6e34-42f2-9aff-58f4fe3e73d3.jpg" class="card-img-top" alt="Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Yumin Choi
          </div>
          <div class="article-meta-text">
            13 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/77-Multimodal-Prompt-Optimization-Why-Not-Leverage-Multiple-Modalities-for-MLLMs/index.html"  title="Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs">
          <h3 class="card-title pb-2" itemprop="headline">Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs</h3>
        </a>
        <a 
          href="/paperium-articles/articles/77-Multimodal-Prompt-Optimization-Why-Not-Leverage-Multiple-Modalities-for-MLLMs/index.html"
          title="Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

       </div>
   </div>
        </article>
        
 

     
    </div>
    </div>
    </div>
  <script src="/paperium-articles/assets/script1.js"></script>
 
</body>
</html>