<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <link rel="stylesheet" href="/paperium-articles/assets/article_detail.css"> 

<title>Beyond Turn Limits: Training Deep Search Agents with Dynamic</title>

<meta name="keywords" content="DeepMiner framework,  multi-turn reasoning agents,  long-horizon interactions,  dynamic context management,  reinforcement learning for reasoning,  hi">

<meta name="description" content="DeepMiner framework,  multi-turn reasoning agents,  long-horizon interactions,  dynamic context management,  reinforcement learning for reasoning,  hi">

</head>
<body>
    <div class="container my-5">
        <div class="row">
    <div class="header-nav text-center">
        <a href="/">Home</a> 
        <span class="separator">|</span> 
        <a href="#">Article</a> 
    </div>

    <div class="article-container">
        <div class="article-tags-row">
            <span class="article-category-badge ">Artificial Intelligence</span>
            <span class="article-category-badge">arXiv</span>
        </div>
        <article id="MainArticle" class="details-body customeArticle" itemscope itemtype="https://schema.org/Article">
            <h1 itemprop="headline" class="article-title">
                Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window
            </h1> 

            <div class="article-author-row">
                <span class="author-name">
                    <img src="/paperium-articles/assets/avatar.png" alt="Author" class="author-icon"> 
                    <span class="authorList">
                        Qiaoyu Tang, Hao Xiang, Le Yu, Bowen Yu, Yaojie Lu, Xianpei Han, Le Sun, WenJuan Zhang, Pengbo Wang, Shixuan Liu, Zhenru Zhang, Jianhong Tu, Hongyu Lin, Junyang Lin
                    </span>
                </span>
            </div>
            <p class="publish-date">
                              13 Oct 2025&nbsp;&nbsp;&nbsp;&nbsp;  3 min read 
            </p>
                            <div class="article-image-wrapper">
                                <figure id="authorsImage"  >
                                    <img class="article-main-image" itemprop="image" src="https://paperium.net/Media/Articles/img/57_88e59798-f6d7-4dcd-b41a-bd04a7b439a6.jpg" class="object-center object-cover" 
                                    alt="undefined" >
                                </figure>
                                 <p class="image-caption">AI-generated image, based on the article abstract</p>
                            </div>

            <div id="QuickInsightWapper" class="mb-4"  itemprop="abstract">
               <h2>
     
     <svg fill="#000000" width="30px" height="30px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg">
<title>paper-plane</title>
<path d="M0 14.016l9.216 6.912 18.784-16.928-14.592 20.064 10.592 7.936 8-32zM8 32l6.016-4-6.016-4v8z"></path>
</svg>
   Quick Insight
       </h2>
            <h3>New AI Trick Lets Chatbots Remember Longer Conversations</h3>
<p>
Ever wondered why virtual assistants sometimes forget what you just asked? <strong>Scientists have discovered</strong> a clever way to give them a memory boost. By training a system called <strong>DeepMiner</strong> with ultra‚Äëhard puzzles and a ‚Äúsliding window‚Äù that constantly shifts the focus, the AI can keep track of almost a hundred back‚Äëand‚Äëforth exchanges without losing the thread. Imagine a notebook that automatically flips pages as you write, so you never run out of space‚Äî that‚Äôs how the dynamic context window works. This breakthrough means search‚Äëhelp bots can stay on topic for much longer, delivering more accurate answers and smoother chats. The result? A jump from ordinary performance to a striking 33.5% success rate on tough benchmark tests, beating the previous best by nearly 20 points. <strong>It‚Äôs a game‚Äëchanger</strong> for everyday tools like voice assistants, customer‚Äëservice chats, and online search helpers. As AI learns to think more like us, the line between human conversation and machine dialogue keeps getting brighter. üåü
</p>
           </div> 
           <hr/>
  <div id="ShortReviewWapper" class="mb-4" itemprop="articleBody">
 <h2>
     <svg fill="#000000" width="30px" height="30px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg">
<title>paper-plane</title>
<path d="M0 14.016l9.216 6.912 18.784-16.928-14.592 20.064 10.592 7.936 8-32zM8 32l6.016-4-6.016-4v8z"></path>
</svg>
   Short Review
       </h2>
        <h2>Advancing Long-Horizon Reasoning in Multi-Turn AI Agents with DeepMiner</h2>

<p>The article introduces <strong>DeepMiner</strong>, a novel framework designed to enhance deep reasoning capabilities in multi-turn AI agents engaged in long-horizon interactions. Existing models often struggle with maintaining coherence and depth over extended conversational or task sequences, primarily due to limitations in handling continuously expanding contexts. DeepMiner addresses this by integrating a sophisticated training data generation method with an efficient context management strategy.</p>

<p>The core methodology involves two key innovations: a reverse construction method for generating high-difficulty, verifiable question-answer pairs from authentic web sources, and a dynamic sliding-window context manager. This approach enables the model to process complex information and sustain reasoning traces without relying on external summarization tools. Trained using reinforcement learning on Qwen3-32B, the resulting DeepMiner-32B agent demonstrates significant performance improvements across several challenging search agent benchmarks.</p>

<p>Specifically, DeepMiner achieves a 33.5% accuracy on BrowseComp-en, marking a nearly 20 percentage point lead over previous open-source agents. Consistent gains are also observed on BrowseComp-zh, XBench-DeepSearch, and GAIA. Crucially, its dynamic context management strategy facilitates sustained interactions of nearly 100 turns within a standard 32k context length, effectively overcoming a major bottleneck for current multi-turn interaction systems.</p>

<h2>Critical Evaluation of DeepMiner's Approach</h2>

<h3>Strengths</h3>
<p>DeepMiner's primary strength lies in its innovative approach to both data generation and context management. The <strong>reverse construction method</strong> for creating high-difficulty, multi-source QA pairs is particularly robust, ensuring that training data genuinely requires extended cross-document reasoning. This directly addresses the need for complex task data to foster advanced web-agent cognition, moving beyond simpler datasets like HotpotQA.</p>
<p>Furthermore, the <strong>dynamic sliding-window context manager</strong> is an elegant and efficient solution to the long-horizon interaction problem. By preserving reasoning traces without external summarization, it significantly reduces computational overhead and maintains the integrity of information over many turns. This strategy enables the agent to handle nearly 100 turns within typical context limits, a substantial improvement over existing systems.</p>
<p>The empirical results are compelling, showcasing substantial performance gains over other open-source agents and narrowing the gap with proprietary systems. The two-stage training pipeline, combining supervised fine-tuning with <strong>Group Relative Policy Optimization</strong>, provides a solid foundation for robust agent development.</p>

<h3>Weaknesses</h3>
<p>While impressive, the article could benefit from further exploration of the generalizability of its findings. The reliance on Qwen3-32B as the base model, though powerful, raises questions about how DeepMiner would perform with other foundational models. Additionally, the binary reward scheme (1 for correct, 0 for incorrect) in the reinforcement learning phase, while effective, might oversimplify the nuances of complex reasoning tasks, potentially overlooking partial successes or sophisticated intermediate steps.</p>
<p>The complexity and resource intensity of the multi-stage QA pair generation pipeline, involving entity-driven collection, multi-source synthesis, and rigorous filtering, could also be a practical limitation for broader adoption or replication by researchers with fewer computational resources.</p>

<h3>Implications</h3>
<p>DeepMiner represents a significant step forward in developing more capable and efficient <strong>multi-turn reasoning agents</strong>. Its innovations in data generation and context handling offer practical solutions to long-standing challenges in AI. The framework's ability to sustain deep interactions over extended horizons has profound implications for applications requiring sophisticated web search, complex problem-solving, and advanced conversational AI, potentially leading to more intelligent and reliable AI assistants.</p>

<h2>Conclusion</h2>
<p>DeepMiner offers a compelling and effective framework for enhancing <strong>long-horizon reasoning</strong> in AI agents. By tackling the dual challenges of generating high-quality, complex training data and efficiently managing dynamic contexts, it significantly pushes the boundaries of what open-source agents can achieve. This work not only delivers substantial performance improvements but also provides valuable insights into the design of future AI systems capable of more profound and sustained cognitive behaviors.</p>
  </div>
  <div id = "keywordsWapper" class="mb-4">
    <h3>Keywords</h3>
    <ul>
  <li>DeepMiner framework</li><li> multi-turn reasoning agents</li><li> long-horizon interactions</li><li> dynamic context management</li><li> reinforcement learning for reasoning</li><li> high-difficulty training tasks</li><li> reverse construction Q&A generation</li><li> context window optimization</li><li> search agent benchmarks</li><li> cognitive capabilities in AI</li><li> sliding window context</li><li> Qwen3-32B fine-tuning</li><li> addressing context limitations</li><li> verifiable training data</li><li> deep reasoning capabilities</li>
</ul>

  </div>
  <div id="linktoWebsiteWrapper">
   <p>
Read article comprehensive review in Paperium.net:
<a href="https://paperium.net/article/en/72/beyond-turn-limits-training-deep-search-agents-with-dynamic-context-window" target="_blank" title=" Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window">
    Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window
</a>
</p> 
 
</div>

<p class="mt-5">
    ü§ñ This analysis and review was primarily generated and structured by an AI . The content is provided for informational and quick-review purposes.
</p>
            <div class="my-5">
       <h2 class="lead text-center mb-5">Paperium AI Analysis & Review of Latest Scientific Research Articles </h2>
<h3>More Artificial Intelligence Article Reviews </h3>
       <div class="row row-cols-1 row-cols-md-2 row-cols-lg-3 g-4" id="articles-container" itemscope itemtype="https://schema.org/ItemList" >

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/99_2eb3654c-72f6-4e46-b53d-c97520a14e1a.jpg" class="card-img-top" alt="ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer
Review" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Gaurav Sahu
          </div>
          <div class="article-meta-text">
            13 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/95-ReviewerToo-Should-AI-Join-The-Program-Committee-A-Look-At-The-Future-of-Peer-Review/index.html"  title="ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer
Review">
          <h3 class="card-title pb-2" itemprop="headline">ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer
Review</h3>
        </a>
        <a 
          href="/paperium-articles/articles/95-ReviewerToo-Should-AI-Join-The-Program-Committee-A-Look-At-The-Future-of-Peer-Review/index.html"
          title="ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer
Review"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/190_04da4b95-7f85-4b2c-bf73-551d84644589.jpg" class="card-img-top" alt="Graph Diffusion Transformers are In-Context Molecular Designers" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Gang Liu
          </div>
          <div class="article-meta-text">
            14 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/179-Graph-Diffusion-Transformers-are-In-Context-Molecular-Designers/index.html"  title="Graph Diffusion Transformers are In-Context Molecular Designers">
          <h3 class="card-title pb-2" itemprop="headline">Graph Diffusion Transformers are In-Context Molecular Designers</h3>
        </a>
        <a 
          href="/paperium-articles/articles/179-Graph-Diffusion-Transformers-are-In-Context-Molecular-Designers/index.html"
          title="Graph Diffusion Transformers are In-Context Molecular Designers"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/114_8601622f-4906-497f-864d-aec361ea0260.jpg" class="card-img-top" alt="ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Jiayu Yang
          </div>
          <div class="article-meta-text">
            13 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/110-ACE-Attribution-Controlled-Knowledge-Editing-for-Multi-hop-Factual-Recall/index.html"  title="ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall">
          <h3 class="card-title pb-2" itemprop="headline">ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall</h3>
        </a>
        <a 
          href="/paperium-articles/articles/110-ACE-Attribution-Controlled-Knowledge-Editing-for-Multi-hop-Factual-Recall/index.html"
          title="ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/112_1c7e1ac6-740c-42f5-a8c2-2cd7b719536f.jpg" class="card-img-top" alt="Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal
Models" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Sharut Gupta
          </div>
          <div class="article-meta-text">
            13 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/108-Better-Together-Leveraging-Unpaired-Multimodal-Data-for-Stronger-Unimodal-Models/index.html"  title="Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal
Models">
          <h3 class="card-title pb-2" itemprop="headline">Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal
Models</h3>
        </a>
        <a 
          href="/paperium-articles/articles/108-Better-Together-Leveraging-Unpaired-Multimodal-Data-for-Stronger-Unimodal-Models/index.html"
          title="Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal
Models"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/161_61570f6e-c2dc-4556-9d9f-07f86154e85f.jpg" class="card-img-top" alt="Building a Foundational Guardrail for General Agentic Systems via Synthetic Data" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Yue Huang
          </div>
          <div class="article-meta-text">
            14 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/150-Building-a-Foundational-Guardrail-for-General-Agentic-Systems-via-Synthetic-Data/index.html"  title="Building a Foundational Guardrail for General Agentic Systems via Synthetic Data">
          <h3 class="card-title pb-2" itemprop="headline">Building a Foundational Guardrail for General Agentic Systems via Synthetic Data</h3>
        </a>
        <a 
          href="/paperium-articles/articles/150-Building-a-Foundational-Guardrail-for-General-Agentic-Systems-via-Synthetic-Data/index.html"
          title="Building a Foundational Guardrail for General Agentic Systems via Synthetic Data"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/168_93ab7fe2-620f-4b65-ba71-d20f6b70e9ee.jpg" class="card-img-top" alt="AdaViewPlanner: Adapting Video Diffusion Models for Viewpoint Planning in 4D
Scenes" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Yu Li
          </div>
          <div class="article-meta-text">
            14 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/157-AdaViewPlanner-Adapting-Video-Diffusion-Models-for-Viewpoint-Planning-in-4D-Scenes/index.html"  title="AdaViewPlanner: Adapting Video Diffusion Models for Viewpoint Planning in 4D
Scenes">
          <h3 class="card-title pb-2" itemprop="headline">AdaViewPlanner: Adapting Video Diffusion Models for Viewpoint Planning in 4D
Scenes</h3>
        </a>
        <a 
          href="/paperium-articles/articles/157-AdaViewPlanner-Adapting-Video-Diffusion-Models-for-Viewpoint-Planning-in-4D-Scenes/index.html"
          title="AdaViewPlanner: Adapting Video Diffusion Models for Viewpoint Planning in 4D
Scenes"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

       </div>
   </div>
        </article>
        
 

     
    </div>
    </div>
    </div>
  <link rel="stylesheet" href="/paperium-articles/assets/script1.js"> 
 
</body>
</html>