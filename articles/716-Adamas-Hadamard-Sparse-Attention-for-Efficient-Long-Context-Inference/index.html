<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <link rel="stylesheet" href="/paperium-articles/assets/article_detail.css?ver=2"> 
    <link rel="stylesheet" href="/paperium-articles/assets/StyleSheet.css?ver=2" >

<title>Adamas: Hadamard Sparse Attention for Efficient Long-Context</title>

<meta name="keywords" content="large language models long-context attention,  sparse attention mechanisms for LLMs,  Adamas sparse attention algorithm,  Hadamard transform in attent">

<meta name="description" content="large language models long-context attention,  sparse attention mechanisms for LLMs,  Adamas sparse attention algorithm,  Hadamard transform in attent">

</head>
<body>
    <div class="container my-5">
        <div class="row">
    <div class="header-nav text-center">
        <a href="/paperium-articles/">Home</a> 
        <span class="separator">|</span> 
        <a href="#">Article</a> 
    </div>

    <div class="article-container">
        <div class="article-tags-row">
            <span class="article-category-badge ">Artificial Intelligence</span>
            <span class="article-category-badge">arXiv</span>
        </div>
        <article id="MainArticle" class="details-body customeArticle" itemscope itemtype="https://schema.org/Article">
            <h1 itemprop="headline" class="article-title">
                Adamas: Hadamard Sparse Attention for Efficient Long-Context Inference
            </h1> 

            <div class="article-author-row">
                <span class="author-name">
                    <img src="/paperium-articles/assets/avatar.png" alt="Author" class="author-icon"> 
                    <span class="authorList">
                        Siyuan Yan, Guo-Qing Jiang, Yuchen Zhang, Xiaoxing Ma, Ran Zhu, Chun Cao, Jingwei Xu
                    </span>
                </span>
            </div>
            <p class="publish-date">
                              26 Oct 2025&nbsp;&nbsp;&nbsp;&nbsp;  3 min read 
            </p>
                            <div class="article-image-wrapper">
                                <figure id="authorsImage"  >
                                    <img class="article-main-image" itemprop="image" src="https://paperium.net/Media/Articles/img/612_5ffb0136-89af-4f26-b9c6-95f308ff571c.jpg" class="object-center object-cover" 
                                    alt="undefined" >
                                </figure>
                                 <p class="image-caption">AI-generated image, based on the article abstract</p>
                            </div>

            <div id="QuickInsightWapper" class="mb-4"  itemprop="abstract">
               <h2>
     
     <svg fill="#000000" width="30px" height="30px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg">
<title>paper-plane</title>
<path d="M0 14.016l9.216 6.912 18.784-16.928-14.592 20.064 10.592 7.936 8-32zM8 32l6.016-4-6.016-4v8z"></path>
</svg>
   Quick Insight
       </h2>
            <h3>New AI Trick Makes Chatbots Faster on Long Texts</h3>
<p>
Ever wondered how your favorite AI can read an entire novel in a flash? <strong>Scientists have unveiled</strong> a clever shortcut called Adamas that lets huge language models skim massive documents without missing a beat. Imagine trying to find a specific sentence in a 1,000‚Äëpage book; instead of reading every page, you first flip to the chapters most likely to hold the answer. Adamas does the same by turning the text into tiny, compressed ‚Äúsnapshots‚Äù using a special math trick called the Hadamard transform, then quickly picks the most relevant pieces with a simple distance check. The result? The AI keeps the same level of understanding as before while using only a fraction of the computing power‚Äîup to eight times less work than older methods. This means faster replies, smoother long‚Äëform summaries, and even quicker code generation. <strong>This breakthrough</strong> shows that smarter, not bigger, can power the next wave of AI assistants. <strong>Imagine</strong> a world where your chatbot can handle whole books in seconds, keeping conversations natural and lightning‚Äëquick. The future of AI just got a lot more efficient.</p>
           </div> 
           <hr/>
  <div id="ShortReviewWapper" class="mb-4" itemprop="articleBody">
 <h2>
     <svg fill="#000000" width="30px" height="30px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg">
<title>paper-plane</title>
<path d="M0 14.016l9.216 6.912 18.784-16.928-14.592 20.064 10.592 7.936 8-32zM8 32l6.016-4-6.016-4v8z"></path>
</svg>
   Short Review
       </h2>
        <h2>Optimizing Long-Context Inference in Large Language Models with Adamas</h2>

<p>The increasing demand for Large Language Models (LLMs) to process extensive context windows, spanning hundreds of thousands to millions of tokens, presents a significant computational challenge. This article introduces <strong>Adamas</strong>, an innovative sparse attention mechanism specifically engineered to address the quadratic cost of self-attention, which typically leads to severe latency during autoregressive decoding. Unlike prior sparse attention methods that often compromise accuracy due to reliance on heuristic patterns, Adamas leverages a sophisticated combination of the <strong>Hadamard transform</strong>, bucketization, and 2-bit compression to create compact representations. It further employs Manhattan-distance estimation for efficient top-k selections, aiming to maintain high accuracy while drastically improving inference speed for long sequences.</p>

<h2>Critical Evaluation of Adamas's Performance and Design</h2>

<h3>Strengths of the Adamas Sparse Attention Mechanism</h3>
<p>Adamas demonstrates remarkable strengths in tackling the efficiency-accuracy trade-off inherent in long-context LLMs. A primary advantage is its ability to match the accuracy of full attention, even with a highly constrained <strong>64-token budget</strong>, and achieve near-lossless performance at 128 tokens. This is a significant breakthrough, as it supports up to 8x higher sparsity than existing state-of-the-art methods. The mechanism delivers substantial efficiency gains, including up to <strong>4.4x self-attention speedup</strong> and a 1.5x end-to-end speedup on 32K-length sequences. Furthermore, Adamas achieves comparable or even lower perplexity than full attention, underscoring its effectiveness in maintaining accuracy under aggressive sparsity. Its training-free nature, as highlighted in the analysis, also simplifies deployment and integration into existing LLM architectures.</p>

<h3>Potential Considerations and Future Directions</h3>
<p>While Adamas presents a compelling solution, a deeper exploration into its performance at extremely large context windows, beyond the 32K sequences tested, could provide further insights. The abstract mentions context windows of "hundreds of thousands to millions of tokens," and understanding how Adamas scales to these magnitudes, particularly regarding any potential accuracy degradation at the highest sparsity levels, would be valuable. Additionally, while the method is described as lightweight, a more detailed analysis of its memory footprint compared to other sparse attention techniques could offer a more complete picture for practical applications. Future research might also investigate the adaptability of Adamas to diverse LLM architectures and specialized tasks, ensuring its broad applicability across the evolving landscape of large language models.</p>

<h2>Conclusion: Adamas's Impact on LLM Scalability</h2>
<p>Adamas represents a substantial advancement in the field of efficient LLM inference, offering a robust and highly effective solution to the long-standing challenge of quadratic self-attention costs. By ingeniously combining the Hadamard transform with efficient compression and distance estimation, it provides a mechanism that not only significantly boosts processing speed but also preserves, and in some cases improves, accuracy. This innovation is crucial for unlocking the full potential of LLMs in applications requiring extensive context understanding, such as long-document summarization and multi-document question answering. Adamas is poised to play a pivotal role in making <strong>long-context LLMs</strong> more practical, scalable, and accessible for a wide range of scientific and industrial applications.</p>
  </div>
  <div id = "keywordsWapper" class="mb-4">
    <h3>Keywords</h3>
    <ul>
  <li>large language models long-context attention</li><li> sparse attention mechanisms for LLMs</li><li> Adamas sparse attention algorithm</li><li> Hadamard transform in attention compression</li><li> bucketization and 2-bit quantization for KV pairs</li><li> Manhattan-distance top‚Äëk selection</li><li> quadratic self‚Äëattention cost reduction</li><li> autoregressive decoding latency mitigation</li><li> long‚Äëdocument summarization with sparse attention</li><li> multi‚Äëdocument question answering scalability</li><li> persistent multi‚Äëturn dialogue efficiency</li><li> high sparsity ratios in transformer models</li><li> near‚Äëlossless perplexity with aggressive sparsity.</li>
</ul>

  </div>
  <div id="linktoWebsiteWrapper">
   <p>
Read article comprehensive review in Paperium.net:
<a href="https://paperium.net/article/en/716/adamas-hadamard-sparse-attention-for-efficient-long-context-inference" target="_blank" title=" Adamas: Hadamard Sparse Attention for Efficient Long-Context Inference">
    Adamas: Hadamard Sparse Attention for Efficient Long-Context Inference
</a>
</p> 
 
</div>

<p class="mt-5">
    ü§ñ This analysis and review was primarily generated and structured by an AI . The content is provided for informational and quick-review purposes.
</p>
            <div class="my-5" id=similarWrapper>
       <h2 class="lead text-center mb-5" id="similarh2">Paperium AI Analysis & Review of Latest Scientific Research Articles </h2>
<h3 id="similarh3"> More Artificial Intelligence Article Reviews </h3>
       <div class="row row-cols-1 row-cols-md-2 row-cols-lg-3 g-4" id="articles-container" itemscope itemtype="https://schema.org/ItemList" >

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/457_f1973576-e778-4625-947a-5b819c54a038.jpg" class="card-img-top" alt="UltraGen: High-Resolution Video Generation with Hierarchical Attention" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Teng Hu
          </div>
          <div class="article-meta-text">
            22 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/443-UltraGen-High-Resolution-Video-Generation-with-Hierarchical-Attention/index.html"  title="UltraGen: High-Resolution Video Generation with Hierarchical Attention">
          <h3 class="card-title pb-2" itemprop="headline">UltraGen: High-Resolution Video Generation with Hierarchical Attention</h3>
        </a>
        <a 
          href="/paperium-articles/articles/443-UltraGen-High-Resolution-Video-Generation-with-Hierarchical-Attention/index.html"
          title="UltraGen: High-Resolution Video Generation with Hierarchical Attention"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/492_289a2088-1c73-4bbe-8395-93dd63c94af1.jpg" class="card-img-top" alt="Planned Diffusion" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Daniel Israel
          </div>
          <div class="article-meta-text">
            23 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/496-Planned-Diffusion/index.html"  title="Planned Diffusion">
          <h3 class="card-title pb-2" itemprop="headline">Planned Diffusion</h3>
        </a>
        <a 
          href="/paperium-articles/articles/496-Planned-Diffusion/index.html"
          title="Planned Diffusion"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/547_b1189964-39df-4c75-925d-bf32a81c2ebc.jpg" class="card-img-top" alt="Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Mingyu Jo
          </div>
          <div class="article-meta-text">
            24 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/656-Loopholing-Discrete-Diffusion-Deterministic-Bypass-of-the-Sampling-Wall/index.html"  title="Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall">
          <h3 class="card-title pb-2" itemprop="headline">Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall</h3>
        </a>
        <a 
          href="/paperium-articles/articles/656-Loopholing-Discrete-Diffusion-Deterministic-Bypass-of-the-Sampling-Wall/index.html"
          title="Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/488_0788b4bf-a7c9-47af-978f-a1d07ec954c0.jpg" class="card-img-top" alt="DeepSeek-OCR: Contexts Optical Compression" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Haoran Wei
          </div>
          <div class="article-meta-text">
            23 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/492-DeepSeek-OCR-Contexts-Optical-Compression/index.html"  title="DeepSeek-OCR: Contexts Optical Compression">
          <h3 class="card-title pb-2" itemprop="headline">DeepSeek-OCR: Contexts Optical Compression</h3>
        </a>
        <a 
          href="/paperium-articles/articles/492-DeepSeek-OCR-Contexts-Optical-Compression/index.html"
          title="DeepSeek-OCR: Contexts Optical Compression"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/532_c3823834-974f-46d5-bbb9-699434b3da56.jpg" class="card-img-top" alt="Steering Autoregressive Music Generation with Recursive Feature Machines" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Daniel Zhao
          </div>
          <div class="article-meta-text">
            24 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/642-Steering-Autoregressive-Music-Generation-with-Recursive-Feature-Machines/index.html"  title="Steering Autoregressive Music Generation with Recursive Feature Machines">
          <h3 class="card-title pb-2" itemprop="headline">Steering Autoregressive Music Generation with Recursive Feature Machines</h3>
        </a>
        <a 
          href="/paperium-articles/articles/642-Steering-Autoregressive-Music-Generation-with-Recursive-Feature-Machines/index.html"
          title="Steering Autoregressive Music Generation with Recursive Feature Machines"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/516_22fbc687-17c5-4d21-8c32-e0c601f06128.jpg" class="card-img-top" alt="Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Yusu Qian
          </div>
          <div class="article-meta-text">
            24 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/626-Pico-Banana-400K-A-Large-Scale-Dataset-for-Text-Guided-Image-Editing/index.html"  title="Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing">
          <h3 class="card-title pb-2" itemprop="headline">Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing</h3>
        </a>
        <a 
          href="/paperium-articles/articles/626-Pico-Banana-400K-A-Large-Scale-Dataset-for-Text-Guided-Image-Editing/index.html"
          title="Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

       </div>
   </div>
        </article>
        
 

     
    </div>
    </div>
    </div>
  <script src="/paperium-articles/assets/script1.js"></script>
 
</body>
</html>