<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <link rel="stylesheet" href="/paperium-articles/assets/article_detail.css"> 

<title>FinAuditing: A Financial Taxonomy-Structured Multi-Document </title>

<meta name="keywords" content="Generally Accepted Accounting Principles,  GAAP compliance,  eXtensible Business Reporting Language,  XBRL filings,  financial auditing automation,  l">

<meta name="description" content="Generally Accepted Accounting Principles,  GAAP compliance,  eXtensible Business Reporting Language,  XBRL filings,  financial auditing automation,  l">

</head>
<body>
    <div class="container my-5">
        <div class="row">
    <div class="header-nav text-center">
        <a href="/">Home</a> 
        <span class="separator">|</span> 
        <a href="#">Article</a> 
    </div>

    <div class="article-container">
        <div class="article-tags-row">
            <span class="article-category-badge ">Artificial Intelligence</span>
            <span class="article-category-badge">arXiv</span>
        </div>
        <article id="MainArticle" class="details-body customeArticle" itemscope itemtype="https://schema.org/Article">
            <h1 itemprop="headline" class="article-title">
                FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark for
Evaluating LLMs
            </h1> 

            <div class="article-author-row">
                <span class="author-name">
                    <img src="/paperium-articles/assets/avatar.png" alt="Author" class="author-icon"> 
                    <span class="authorList">
                        Yan Wang, Keyi Wang, Shanshan Yang, Jaisal Patel, Jeff Zhao, Fengran Mo, Xueqing Peng, Lingfei Qian, Jimin Huang, Guojun Xiong, Xiao-Yang Liu, Jian-Yun Nie
                    </span>
                </span>
            </div>
            <p class="publish-date">
                              14 Oct 2025&nbsp;&nbsp;&nbsp;&nbsp;  3 min read 
            </p>
                            <div class="article-image-wrapper">
                                <figure id="authorsImage"  >
                                    <img class="article-main-image" itemprop="image" src="https://paperium.net/Media/Articles/img/164_6c5418ee-553b-47b5-8281-d34f85e69ec7.jpg" class="object-center object-cover" 
                                    alt="undefined" >
                                </figure>
                                 <p class="image-caption">AI-generated image, based on the article abstract</p>
                            </div>

            <div id="QuickInsightWapper" class="mb-4"  itemprop="abstract">
               <h2>
     
     <svg fill="#000000" width="30px" height="30px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg">
<title>paper-plane</title>
<path d="M0 14.016l9.216 6.912 18.784-16.928-14.592 20.064 10.592 7.936 8-32zM8 32l6.016-4-6.016-4v8z"></path>
</svg>
   Quick Insight
       </h2>
            <h3>FinAuditing: How AI Is Tested on Realâ€‘World Financial Reports</h3>
<p>
Ever wondered if a smart chatbot could spot errors in a companyâ€™s financial statements? <strong>Scientists have built</strong> a new challenge called FinAuditing that puts large language models (the AI behind ChatGPT) to the test with realâ€‘world, taxâ€‘lawâ€‘compliant reports. Instead of just reading plain text, the AI must navigate layered tables, numbers, and relationshipsâ€”much like a detective sorting through a maze of clues. The test checks three things: whether the story in the report makes sense (<strong>semantic consistency</strong>), whether the links between different sections line up (<strong>relational consistency</strong>), and whether the math adds up (<strong>numerical consistency</strong>). Early results show current AIs stumble, dropping up to 90% in accuracy when faced with these complex, multiâ€‘page documents. This tells us that while AI can chat fluently, it still has a long way to go before it can reliably audit finances. As we move toward smarter, regulationâ€‘aware tools, benchmarks like FinAuditing will be the compass guiding us toward safer, more trustworthy financial AI. ðŸŒŸ
</p>
           </div> 
           <hr/>
  <div id="ShortReviewWapper" class="mb-4" itemprop="articleBody">
 <h2>
     <svg fill="#000000" width="30px" height="30px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg">
<title>paper-plane</title>
<path d="M0 14.016l9.216 6.912 18.784-16.928-14.592 20.064 10.592 7.936 8-32zM8 32l6.016-4-6.016-4v8z"></path>
</svg>
   Short Review
       </h2>
        <h2>Overview</h2>
<p>The article introduces <strong>FinAuditing</strong>, a pioneering benchmark aimed at evaluating large language models (LLMs) in the context of financial auditing. It addresses the complexities associated with Generally Accepted Accounting Principles (GAAP) and eXtensible Business Reporting Language (XBRL) filings, which complicate automation and verification processes. The benchmark delineates three specific subtasks: Financial Semantic Matching (FinSM), Financial Relationship Extraction (FinRE), and Financial Mathematical Reasoning (FinMR), each targeting distinct aspects of structured auditing. The findings reveal significant performance gaps in current LLMs, with accuracy drops of up to 60-90% when handling hierarchical multi-document structures, underscoring the need for enhanced financial reasoning systems.</p>

<h3>Critical Evaluation</h3>
<h3>Strengths</h3>
<p>One of the primary strengths of the article is its comprehensive approach to addressing the limitations of existing benchmarks in financial auditing. By introducing <strong>FinAuditing</strong>, the authors provide a structured framework that not only evaluates LLMs on semantic, relational, and numerical consistency but also aligns with the complexities of real-world financial data. The use of real US-GAAP-compliant XBRL filings enhances the relevance and applicability of the benchmark, making it a valuable resource for future research and development in financial intelligence systems.</p>

<h3>Weaknesses</h3>
<p>Despite its strengths, the article does exhibit some weaknesses. The performance evaluation of various LLMs indicates that even state-of-the-art models struggle significantly with the subtasks defined in <strong>FinAuditing</strong>. This raises questions about the current capabilities of LLMs in handling structured financial data, suggesting a potential bias towards models that may not be adequately trained for such tasks. Furthermore, the reliance on specific metrics like Hit Rate and Macro F1 may not fully capture the nuances of financial reasoning, potentially limiting the benchmark's effectiveness.</p>

<h3>Implications</h3>
<p>The implications of this research are profound, as it highlights the urgent need for improved <strong>financial reasoning</strong> capabilities in LLMs. The findings suggest that without addressing the systematic limitations identified, the deployment of LLMs in financial auditing could lead to significant errors and misinterpretations. This benchmark sets the stage for future advancements in developing trustworthy, structure-aware financial intelligence systems that align with regulatory standards.</p>

<h3>Conclusion</h3>
<p>In summary, the article presents a critical advancement in the evaluation of LLMs for financial auditing through the introduction of <strong>FinAuditing</strong>. While it successfully identifies key performance gaps and establishes a foundation for future research, it also underscores the challenges that remain in achieving reliable financial reasoning. The benchmark's availability at Hugging Face further enhances its potential impact on the field, encouraging ongoing exploration and development in this vital area of financial technology.</p>

<h3>Readability</h3>
<p>The article is structured to facilitate understanding, with clear definitions and a logical flow of information. Each section builds upon the previous one, making it accessible to a professional audience. The use of concise paragraphs and straightforward language enhances engagement, ensuring that readers can easily grasp the complexities of financial auditing and the role of LLMs within it.</p>
  </div>
  <div id = "keywordsWapper" class="mb-4">
    <h3>Keywords</h3>
    <ul>
  <li>Generally Accepted Accounting Principles</li><li> GAAP compliance</li><li> eXtensible Business Reporting Language</li><li> XBRL filings</li><li> financial auditing automation</li><li> large language models in finance</li><li> FinAuditing benchmark</li><li> structured financial documents</li><li> semantic consistency in auditing</li><li> relational consistency in financial reporting</li><li> numerical consistency in auditing</li><li> taxonomy-driven financial reasoning</li><li> multi-document auditing tasks</li><li> evaluation framework for LLMs</li><li> zero-shot learning in finance</li>
</ul>

  </div>
  <div id="linktoWebsiteWrapper">
   <p>
Read article comprehensive review in Paperium.net:
<a href="https://paperium.net/article/en/153/finauditing-a-financial-taxonomy-structured-multi-document-benchmark-forevaluating-llms" target="_blank" title=" FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark for
Evaluating LLMs">
    FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark for
Evaluating LLMs
</a>
</p> 
 
</div>

<p class="mt-5">
    ðŸ¤– This analysis and review was primarily generated and structured by an AI . The content is provided for informational and quick-review purposes.
</p>
            <div class="my-5">
       <h2 class="lead text-center mb-5">Paperium AI Analysis & Review of Latest Scientific Research Articles </h2>
<h3>More Artificial Intelligence Article Reviews </h3>
       <div class="row row-cols-1 row-cols-md-2 row-cols-lg-3 g-4" id="articles-container" itemscope itemtype="https://schema.org/ItemList" >

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/164_6c5418ee-553b-47b5-8281-d34f85e69ec7.jpg" class="card-img-top" alt="FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark for
Evaluating LLMs" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Yan Wang
          </div>
          <div class="article-meta-text">
            14 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/153-FinAuditing-A-Financial-Taxonomy-Structured-Multi-Document-Benchmark-for-Evaluating-LLMs/index.html"  title="FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark for
Evaluating LLMs">
          <h3 class="card-title pb-2" itemprop="headline">FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark for
Evaluating LLMs</h3>
        </a>
        <a 
          href="/paperium-articles/articles/153-FinAuditing-A-Financial-Taxonomy-Structured-Multi-Document-Benchmark-for-Evaluating-LLMs/index.html"
          title="FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark for
Evaluating LLMs"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/169_e746a935-1781-4533-b7fd-22e08f598e2c.jpg" class="card-img-top" alt="Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Ganlin Yang
          </div>
          <div class="article-meta-text">
            14 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/158-Vlaser-Vision-Language-Action-Model-with-Synergistic-Embodied-Reasoning/index.html"  title="Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning">
          <h3 class="card-title pb-2" itemprop="headline">Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning</h3>
        </a>
        <a 
          href="/paperium-articles/articles/158-Vlaser-Vision-Language-Action-Model-with-Synergistic-Embodied-Reasoning/index.html"
          title="Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/172_c6e94e1e-7126-4041-a044-2ddeb233d696.jpg" class="card-img-top" alt="On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large
Vision-Language Models" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Hoigi Seo
          </div>
          <div class="article-meta-text">
            14 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/161-On-Epistemic-Uncertainty-of-Visual-Tokens-for-Object-Hallucinations-in-Large-Vision-Language-Mod/index.html"  title="On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large
Vision-Language Models">
          <h3 class="card-title pb-2" itemprop="headline">On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large
Vision-Language Models</h3>
        </a>
        <a 
          href="/paperium-articles/articles/161-On-Epistemic-Uncertainty-of-Visual-Tokens-for-Object-Hallucinations-in-Large-Vision-Language-Mod/index.html"
          title="On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large
Vision-Language Models"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/49_7b075104-8ea4-4e08-8654-05625a71b853.jpg" class="card-img-top" alt="UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Xiangyu Peng
          </div>
          <div class="article-meta-text">
            13 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/40-UNIDOC-BENCH-A-Unified-Benchmark-for-Document-Centric-Multimodal-RAG/index.html"  title="UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG">
          <h3 class="card-title pb-2" itemprop="headline">UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG</h3>
        </a>
        <a 
          href="/paperium-articles/articles/40-UNIDOC-BENCH-A-Unified-Benchmark-for-Document-Centric-Multimodal-RAG/index.html"
          title="UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/154_b49f1540-f8ce-4c87-920d-a3a5da4057a8.jpg" class="card-img-top" alt="RLFR: Extending Reinforcement Learning for LLMs with Flow Environment" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Jinghao Zhang
          </div>
          <div class="article-meta-text">
            14 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/143-RLFR-Extending-Reinforcement-Learning-for-LLMs-with-Flow-Environment/index.html"  title="RLFR: Extending Reinforcement Learning for LLMs with Flow Environment">
          <h3 class="card-title pb-2" itemprop="headline">RLFR: Extending Reinforcement Learning for LLMs with Flow Environment</h3>
        </a>
        <a 
          href="/paperium-articles/articles/143-RLFR-Extending-Reinforcement-Learning-for-LLMs-with-Flow-Environment/index.html"
          title="RLFR: Extending Reinforcement Learning for LLMs with Flow Environment"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/102_88b36667-a795-4724-a4e2-299dee87a3b0.jpg" class="card-img-top" alt="Mind-Paced Speaking: A Dual-Brain Approach to Real-Time Reasoning in Spoken
Language Models" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Donghang Wu
          </div>
          <div class="article-meta-text">
            13 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/98-Mind-Paced-Speaking-A-Dual-Brain-Approach-to-Real-Time-Reasoning-in-Spoken-Language-Models/index.html"  title="Mind-Paced Speaking: A Dual-Brain Approach to Real-Time Reasoning in Spoken
Language Models">
          <h3 class="card-title pb-2" itemprop="headline">Mind-Paced Speaking: A Dual-Brain Approach to Real-Time Reasoning in Spoken
Language Models</h3>
        </a>
        <a 
          href="/paperium-articles/articles/98-Mind-Paced-Speaking-A-Dual-Brain-Approach-to-Real-Time-Reasoning-in-Spoken-Language-Models/index.html"
          title="Mind-Paced Speaking: A Dual-Brain Approach to Real-Time Reasoning in Spoken
Language Models"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

       </div>
   </div>
        </article>
        
 

     
    </div>
    </div>
    </div>
  <link rel="stylesheet" href="/paperium-articles/assets/script1.js"> 
 
</body>
</html>