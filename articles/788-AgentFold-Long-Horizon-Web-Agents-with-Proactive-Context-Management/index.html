<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <link rel="stylesheet" href="/paperium-articles/assets/article_detail.css?ver=2"> 
    <link rel="stylesheet" href="/paperium-articles/assets/StyleSheet.css?ver=2" >

<title>AgentFold: Long-Horizon Web Agents with Proactive Context Ma</title>

<meta name="keywords" content="LLM web agents for long-horizon information seeking,  context saturation in ReAct agents,  dynamic cognitive workspace for LLM agents,  proactive cont">

<meta name="description" content="LLM web agents for long-horizon information seeking,  context saturation in ReAct agents,  dynamic cognitive workspace for LLM agents,  proactive cont">

</head>
<body>
    <div class="container my-5">
        <div class="row">
    <div class="header-nav text-center">
        <a href="/paperium-articles/">Home</a> 
        <span class="separator">|</span> 
        <a href="#">Article</a> 
    </div>

    <div class="article-container">
        <div class="article-tags-row">
            <span class="article-category-badge ">Artificial Intelligence</span>
            <span class="article-category-badge">arXiv</span>
        </div>
        <article id="MainArticle" class="details-body customeArticle" itemscope itemtype="https://schema.org/Article">
            <h1 itemprop="headline" class="article-title">
                AgentFold: Long-Horizon Web Agents with Proactive Context Management
            </h1> 

            <div class="article-author-row">
                <span class="author-name">
                    <img src="/paperium-articles/assets/avatar.png" alt="Author" class="author-icon"> 
                    <span class="authorList">
                        Rui Ye, Zhongwang Zhang, Kuan Li, Huifeng Yin, Zhengwei Tao, Yida Zhao, Liangcai Su, Liwen Zhang, Zile Qiao, Xinyu Wang, Pengjun Xie, Fei Huang, Siheng Chen, Jingren Zhou, Yong Jiang
                    </span>
                </span>
            </div>
            <p class="publish-date">
                              29 Oct 2025&nbsp;&nbsp;&nbsp;&nbsp;  3 min read 
            </p>
                            <div class="article-image-wrapper">
                                <figure id="authorsImage"  >
                                    <img class="article-main-image" itemprop="image" src="https://paperium.net/Media/Articles/img/695_f5e8616d-9815-48a1-9c94-249aad3a554c.jpg" class="object-center object-cover" 
                                    alt="undefined" >
                                </figure>
                                 <p class="image-caption">AI-generated image, based on the article abstract</p>
                            </div>

            <div id="QuickInsightWapper" class="mb-4"  itemprop="abstract">
               <h2>
     
     <svg fill="#000000" width="30px" height="30px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg">
<title>paper-plane</title>
<path d="M0 14.016l9.216 6.912 18.784-16.928-14.592 20.064 10.592 7.936 8-32zM8 32l6.016-4-6.016-4v8z"></path>
</svg>
   Quick Insight
       </h2>
            <h3>AgentFold: How Smart Web Helpers Remember What Matters</h3>
<p>
Ever wonder why some AI assistants lose track of a long conversation? <strong>AgentFold</strong> changes that by giving web‚Äëagents a clever way to ‚Äúfold‚Äù their memory, just like you might fold a paper notebook to keep the most important notes handy. Instead of stuffing every click and answer into a growing list, this new approach actively reshapes its memory, keeping key details crisp while safely tucking away older steps. Imagine a traveler who packs a suitcase: the most useful items stay on top, while the rest are neatly rolled and stored away. The result? The AI can handle complex, multi‚Äëstep web searches without getting confused, beating even much larger models and big‚Äëbrand assistants. This breakthrough means future chatbots could help you plan trips, research topics, or shop online with far fewer mix‚Äëups. <strong>Scientists found</strong> that a modestly sized model using AgentFold outperformed heavyweight rivals, proving that smarter memory beats bigger size. <strong>It‚Äôs a glimpse</strong> of a future where digital helpers stay focused, reliable, and truly useful every time you ask.<br><br>
The next time you chat with an AI, imagine it folding its thoughts just for you.
</p>
           </div> 
           <hr/>
  <div id="ShortReviewWapper" class="mb-4" itemprop="articleBody">
 <h2>
     <svg fill="#000000" width="30px" height="30px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg">
<title>paper-plane</title>
<path d="M0 14.016l9.216 6.912 18.784-16.928-14.592 20.064 10.592 7.936 8-32zM8 32l6.016-4-6.016-4v8z"></path>
</svg>
   Short Review
       </h2>
        <h2>Overview of AgentFold's Proactive Context Management for LLM Agents</h2>
<p>This groundbreaking article introduces <strong>AgentFold</strong>, a novel paradigm for <strong>LLM-based web agents</strong> designed to overcome the inherent challenges of <strong>context management</strong> in <strong>long-horizon tasks</strong>. Traditional agents often suffer from context saturation or irreversible information loss, hindering their effectiveness. Inspired by human cognitive processes of retrospective consolidation, AgentFold proposes a dynamic cognitive workspace that actively sculpts its historical trajectory rather than passively logging it. The core methodology involves "folding" operations, which include granular condensations for fine-grained details and deep consolidations for abstracting multi-step sub-tasks. Through <strong>Supervised Fine-Tuning (SFT)</strong>, AgentFold learns to internalize this proactive context curation skill, leading to remarkable performance improvements.</p>

<h2>Critical Evaluation of AgentFold's Performance and Methodology</h2>

<h3>Strengths: Novelty and Efficiency in LLM Agents</h3>
<p>AgentFold presents a significant advancement in <strong>LLM agent design</strong> by introducing a truly <strong>proactive context management</strong> system. Its inspiration from human cognition provides a robust conceptual foundation, moving beyond passive context accumulation. The multi-scale folding operations, encompassing both granular and deep consolidations, effectively balance detail retention with the prevention of context inflation, a critical trade-off in complex tasks. This approach results in exceptional <strong>computational efficiency</strong>, demonstrating sub-linear growth in context size and achieving a 92% reduction in tokens compared to ReAct-based agents. Furthermore, the empirical results are compelling: <strong>AgentFold-30B-A3B</strong> achieves <strong>state-of-the-art performance</strong> on prominent <strong>BrowseComp benchmarks</strong>, notably surpassing larger open-source models and even leading proprietary agents like OpenAI's o4-mini, all achieved with relatively simple SFT without extensive pre-training or reinforcement learning.</p>

<h3>Weaknesses: Potential Limitations and Future Directions</h3>
<p>While AgentFold's performance is impressive, the reliance solely on <strong>Supervised Fine-Tuning (SFT)</strong>, without continual pre-training or reinforcement learning (RL), might suggest a ceiling to its ultimate performance or generalizability across an even broader spectrum of unseen, highly diverse long-horizon tasks. The complexity of the "Fold-Generator" and the training data curation process, though effective, could present challenges for replication or adaptation to new domains without significant effort. Additionally, the article primarily focuses on web browsing tasks; its efficacy and efficiency in other complex domains, such as scientific discovery or creative writing, would require further validation. Future work exploring the integration of RL could potentially unlock even greater adaptability and robustness.</p>

<h3>Implications: Advancing Scalable AI Agents</h3>
<p>The implications of AgentFold are substantial for the future of <strong>LLM-based web agents</strong> and AI systems requiring sustained interaction. By effectively addressing the <strong>context saturation</strong> problem, AgentFold paves the way for more scalable, robust, and cost-effective AI assistants capable of tackling increasingly complex, <strong>long-horizon tasks</strong>. Its ability to maintain a significantly smaller context while achieving superior performance translates directly into reduced computational costs and memory footprints, making advanced AI agents more accessible and deployable. This paradigm shift towards active, human-inspired context curation could inspire new research directions in cognitive AI and agent architecture, fostering the development of truly intelligent and autonomous systems.</p>

<h2>Conclusion: AgentFold's Impact on Web Agent Development</h2>
<p>In conclusion, AgentFold represents a pivotal advancement in the field of <strong>LLM-based web agents</strong>, offering an elegant and highly effective solution to the persistent challenge of <strong>context management</strong> in <strong>long-horizon tasks</strong>. Its novel approach, inspired by human cognition and validated by <strong>state-of-the-art performance</strong> on key benchmarks, underscores the power of proactive context folding. The demonstrated <strong>computational efficiency</strong> and superior task completion rates position AgentFold as a leading paradigm, setting a new standard for designing intelligent agents that can navigate complex, multi-step interactions with unprecedented effectiveness and scalability. This work significantly contributes to the development of more capable and practical AI systems.</p>
  </div>
  <div id = "keywordsWapper" class="mb-4">
    <h3>Keywords</h3>
    <ul>
  <li>LLM web agents for long-horizon information seeking</li><li> context saturation in ReAct agents</li><li> dynamic cognitive workspace for LLM agents</li><li> proactive context folding operation</li><li> granular condensation of agent history</li><li> deep consolidation of multi-step sub-tasks</li><li> supervised fine-tuning without continual pre-training</li><li> BrowseComp benchmark performance</li><li> BrowseComp-ZH multilingual evaluation</li><li> AgentFold vs DeepSeek-V3.1-671B comparison</li><li> retrospective consolidation in AI agents</li><li> LLM agent context management trade-offs</li><li> RL-free fine-tuning for web agents</li><li> open-source large-scale agent baselines</li><li> human-inspired memory consolidation for LLMs</li>
</ul>

  </div>
  <div id="linktoWebsiteWrapper">
   <p>
Read article comprehensive review in Paperium.net:
<a href="https://paperium.net/article/en/788/agentfold-long-horizon-web-agents-with-proactive-context-management" target="_blank" title=" AgentFold: Long-Horizon Web Agents with Proactive Context Management">
    AgentFold: Long-Horizon Web Agents with Proactive Context Management
</a>
</p> 
 
</div>

<p class="mt-5">
    ü§ñ This analysis and review was primarily generated and structured by an AI . The content is provided for informational and quick-review purposes.
</p>
            <div class="my-5" id=similarWrapper>
       <h2 class="lead text-center mb-5" id="similarh2">Paperium AI Analysis & Review of Latest Scientific Research Articles </h2>
<h3 id="similarh3"> More Artificial Intelligence Article Reviews </h3>
       <div class="row row-cols-1 row-cols-md-2 row-cols-lg-3 g-4" id="articles-container" itemscope itemtype="https://schema.org/ItemList" >

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/790_b2b43901-e15a-4bb1-a2f4-510e7fa74b06.jpg" class="card-img-top" alt="Remote Labor Index: Measuring AI Automation of Remote Work" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Mantas Mazeika
          </div>
          <div class="article-meta-text">
            01 Nov 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/885-Remote-Labor-Index-Measuring-AI-Automation-of-Remote-Work/index.html"  title="Remote Labor Index: Measuring AI Automation of Remote Work">
          <h3 class="card-title pb-2" itemprop="headline">Remote Labor Index: Measuring AI Automation of Remote Work</h3>
        </a>
        <a 
          href="/paperium-articles/articles/885-Remote-Labor-Index-Measuring-AI-Automation-of-Remote-Work/index.html"
          title="Remote Labor Index: Measuring AI Automation of Remote Work"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/679_77592da1-d45b-4db9-9866-95df03900e70.jpg" class="card-img-top" alt="LightBagel: A Light-weighted, Double Fusion Framework for Unified Multimodal
Understanding and Generation" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Zeyu Wang
          </div>
          <div class="article-meta-text">
            29 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/775-LightBagel-A-Light-weighted-Double-Fusion-Framework-for-Unified-Multimodal-Understanding-and-Gen/index.html"  title="LightBagel: A Light-weighted, Double Fusion Framework for Unified Multimodal
Understanding and Generation">
          <h3 class="card-title pb-2" itemprop="headline">LightBagel: A Light-weighted, Double Fusion Framework for Unified Multimodal
Understanding and Generation</h3>
        </a>
        <a 
          href="/paperium-articles/articles/775-LightBagel-A-Light-weighted-Double-Fusion-Framework-for-Unified-Multimodal-Understanding-and-Gen/index.html"
          title="LightBagel: A Light-weighted, Double Fusion Framework for Unified Multimodal
Understanding and Generation"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/770_b03c6179-2c75-467d-a32d-1aea5ae4adfe.jpg" class="card-img-top" alt="Kimi Linear: An Expressive, Efficient Attention Architecture" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Kimi Team
          </div>
          <div class="article-meta-text">
            31 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/867-Kimi-Linear-An-Expressive-Efficient-Attention-Architecture/index.html"  title="Kimi Linear: An Expressive, Efficient Attention Architecture">
          <h3 class="card-title pb-2" itemprop="headline">Kimi Linear: An Expressive, Efficient Attention Architecture</h3>
        </a>
        <a 
          href="/paperium-articles/articles/867-Kimi-Linear-An-Expressive-Efficient-Attention-Architecture/index.html"
          title="Kimi Linear: An Expressive, Efficient Attention Architecture"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/813_cb956f20-4f49-4b0a-80d0-569221b41689.jpg" class="card-img-top" alt="PORTool: Tool-Use LLM Training with Rewarded Tree" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Feijie Wu
          </div>
          <div class="article-meta-text">
            02 Nov 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/904-PORTool-Tool-Use-LLM-Training-with-Rewarded-Tree/index.html"  title="PORTool: Tool-Use LLM Training with Rewarded Tree">
          <h3 class="card-title pb-2" itemprop="headline">PORTool: Tool-Use LLM Training with Rewarded Tree</h3>
        </a>
        <a 
          href="/paperium-articles/articles/904-PORTool-Tool-Use-LLM-Training-with-Rewarded-Tree/index.html"
          title="PORTool: Tool-Use LLM Training with Rewarded Tree"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/821_a6442e69-1161-4ac5-868a-3848030ba344.jpg" class="card-img-top" alt="POWSM: A Phonetic Open Whisper-Style Speech Foundation Model" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Chin-Jou Li
          </div>
          <div class="article-meta-text">
            02 Nov 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/911-POWSM-A-Phonetic-Open-Whisper-Style-Speech-Foundation-Model/index.html"  title="POWSM: A Phonetic Open Whisper-Style Speech Foundation Model">
          <h3 class="card-title pb-2" itemprop="headline">POWSM: A Phonetic Open Whisper-Style Speech Foundation Model</h3>
        </a>
        <a 
          href="/paperium-articles/articles/911-POWSM-A-Phonetic-Open-Whisper-Style-Speech-Foundation-Model/index.html"
          title="POWSM: A Phonetic Open Whisper-Style Speech Foundation Model"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

 <article data-ns-animate="" data-delay="0.3" class="group"
             itemscope itemtype="https://schema.org/Article">
  <div class="col">
    <div class="article-card">
      <img src="https://paperium.net/Media/Articles/img/772_290a4823-b220-4b71-87d4-5904d56832ae.jpg" class="card-img-top" alt="The Quest for Generalizable Motion Generation: Data, Model, and Evaluation" itemprop="image">
      <div class="article-card-body">
        <div class="article-meta">
          <div>
            <span class="article-category-badge">
              Artificial Intelligence
            </span>
          </div>
          <div class="article-meta-text">
            Jing Lin
          </div>
          <div class="article-meta-text">
            31 Oct 2025
          </div>
        </div>
        <a href="/paperium-articles/articles/869-The-Quest-for-Generalizable-Motion-Generation-Data-Model-and-Evaluation/index.html"  title="The Quest for Generalizable Motion Generation: Data, Model, and Evaluation">
          <h3 class="card-title pb-2" itemprop="headline">The Quest for Generalizable Motion Generation: Data, Model, and Evaluation</h3>
        </a>
        <a 
          href="/paperium-articles/articles/869-The-Quest-for-Generalizable-Motion-Generation-Data-Model-and-Evaluation/index.html"
          title="The Quest for Generalizable Motion Generation: Data, Model, and Evaluation"
          target="_blank"
          class="btn btn-read-more mt-2"
          role="button" itemprop="url">
          Read Article
        </a>
      </div>
    </div>
  </div>
  </article>

       </div>
   </div>
        </article>
        
 

     
    </div>
    </div>
    </div>
  <script src="/paperium-articles/assets/script1.js"></script>
 
</body>
</html>